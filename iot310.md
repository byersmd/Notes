# Changelog

This document will provide updates about the course at large if updates were made to the repo outside of what was presented within class, or new changes for future sessions.

## 2017-06-23

- Changed all files that should be labeled `README` to readme files so they can be displayed easily within the browsers.
- Initial changelog file added to course root folder
- Adding a section called **Lab Links** which provides links to all the items used within the lab in case anyone wants to delve further.
- **Lab Links** added to [week1/lab1/README.md](week1/lab1/README.md)
- **Lab Links** added to [week1/lab2/README.md](week1/lab2/README.md)
- Updated following sections to [week1/lab2/README.md](week1/lab2/README.md).
    - What is NPM?
    - MQTT over WebSockets
    - MQTT npm module
    - Setup the Electron Quick Start app


## 2017-06-29

- Changed out MQTT broker to [Mosquitto MQTT Broker](http://test.mosquitto.org/) -- updated in previous labs.
- Finished week2# Welcome to the IOT 310B: Internet of Things: Cloud Computing & Analytics

Data is the key to success in the internet of things. In this course you’ll get an overview of the various techniques used to visualize, present and utilize data effectively, so agents of the internet of things system can drive results. We’ll explore data flow, cleansing, processing and analysis, all of which are critical to producing a result worth investing in by the customer. You’ll take a deep dive on concepts such as distributed computing, storage and end-user client applications, all in the context of the cloud. We’ll concentrate on extracting value from the data collected from devices, and from other relevant data, to generate an event or result.

Topics include:

How to store, process, present and visualize data from the internet of things.
- Setting up microservices in the cloud, including data schema, database, API development and server elements
- Simple and complex visualization tools
- Analysis of datasets 

This course expects that you have taken either Course 1 or Course 2 (preferrably both) of the UW IoT Certification Course (or are familiar with programming and the RPi sensors).

## Disclaimer

The materials of this course are the property of the University of Washington, and
are not to be posted on the internet or other forums.

They are for the personal use of the students attending the course.


## Instructor and Classroom Information

**Online Meeting Room:** [https://uwtest.zoom.us/j/546556168](https://uwtest.zoom.us/j/546556168)

**GitLab Repo Links**
- [Labs](https://gitlab.com/richardjortega/iot-310b-student.git)
- [Slides](https://gitlab.com/richardjortega/iot-310b-slides.git)

**MQTT Public Brokers**

If you run into a situation where a MQTT broker is not responding or refusing connection, feel free to change the broker.

- [IoT Eclipse MQTT Broker](https://iot.eclipse.org/getting-started#tutorials)
- [Mosquitto MQTT Broker](http://test.mosquitto.org/)

**Instructor: Richard Ortega**, Email: [riortega@uw.edu](mailto:riortega@uw.edu)

**TA: Bryan Palmer**, Email: [bpalmer@uw.edu](bpalmer@uw.edu)

**Class Sessions:** Thurdays 6:00 pm - 9:00 pm, PT. June 22nd - August 24th, 2017.

**Class Location:** 2445 140th Avenue N.E., Ste. B-100, Bellevue, WA 98005-1879 (Links to an external site.), Room 210

**In-Class Wi-Fi:**  
SSID: **UW-IoT110-R**  
Password: **piIoT110**  (Note: "I" in IoT is  "capital I" and not "lowercase L")

## Various Links

[UW-PCE IoT Website](https://www.pce.uw.edu/certificates/internet-of-things)  
[Canvas](https://canvas.uw.edu/)  

## Raspberry Pi 3 Information

*Note*: Link is from Course 2

[How to Setup your RPi3](https://gitlab.com/Gislason/iot-210B-student/tree/master/Lab1/PI_SETUP.md)

## Course 3 Required Lab Equipment List

**Note**: [Course 1](https://gitlab.com/iot110/iot110-student/) had more sensors/actuators to use, feel free to use those but primarily we will be using the SenseHAT for collecting data. 

| ITEM #  | DESCRIPTION |  QTY  | COST | COMPONENT | BUY URL| OTHER |
| :-----: | :---------- | :---: | ---: | :--------: | :-----------------| :-------- |
| 1  | Raspberry Pi 3 Kit | 1 | $89.95 | [RaspberryPi3](https://www.raspberrypi.org/) | [Adafruit](https://www.adafruit.com/products/3058) |  [Alternate](https://www.amazon.com/dp/B01C6Q4GLE?psc=1) |      
| 2  | Pi Sensor HAT    | 1 | $39.95 | Sensors | [Adafruit](https://www.adafruit.com/products/2738) | [Astro-Pi](https://astro-pi.org/) |
| 3  | Camera Module V2 | 1 | $29.60 | Sensors | [Amazon](https://www.amazon.com/Raspberry-Pi-Camera-Module-Megapixel/dp/B01ER2SKFS)
| 4  | TFT 5 inch Monitor |	1 | $59.95| | [Adafruit](https://www.adafruit.com/products/2232) | | |
| 5  | HDMI Flat Cable | 1 | $11.29 | | [Adafruit](https://www.adafruit.com/products/2197) | |
| 6  | Logitech Wireless Touch Keyboard K400 | 1 | $24.99 | | [Amazon](https://www.amazon.com/Logitech-920-007119-Wireless-Keyboard-Connected/dp/B014EUQOGK/) |
| 7 | Micro USB Charge Sync GOLD Data Cable | 2 |	$9.98 |	| [Amazon](http://amzn.to/2e49OHk) |
| 8 | Anker 24W Dual USB Wall Charger PowerPort 2 | 1 | $12.49 | | [Amazon](http://amzn.to/2ejevvC) |

## Session Breakdown

Section 1 | Time Allotted | Schedule
----- | ------ | ----
Lecture  | 30 Mins | 6:00-6:30pm
Lab  | 25 Mins | 6:30-6:55pm
Break  | 10 Mins | 6:55-7:05pm
Lab Continued  | 25 Mins | 7:05-7:30pm

Section 2 | Time Allotted | Schedule
----- | ------ | ----
Lecture  | 30 Mins | 7:30-8:00pm
Break  | 10 Mins | 8:00-8:10pm
Lab  | 50 Mins | 8:10-9:00pm

## Syllbus and Labs

Week | Date | Lab | Description
----- | ------ | ---- | -----
W1 | Jun 22 | [Lab 1]() | CENTRAL Edge v1 (NodeJS), CENTRAL FieldView (Electron)
W2 | Jun 29  | [Lab 2]() | CENTRAL Edge v2 (Docker), CENTRAL City API (App Service)
W3 | Jul 06 | [Lab 3]() | CENTRAL Link [Cloud Gateway (IoT Hub) <-> Device Gateway]
W4 | Jul 13 | [Lab 4]() | CENTRAL Citizen Finder (Face)/CENTRAL Citizen Happiness (Emotion)
W5 | Jul 20 | [Lab 5]() | Citizen Engagement Mobile App (Ionic), Mini-Capstone
W6 | Jul 27  | [Lab 6]() | CENTRAL Feedback (LUIS), CENTRAL Feedback Translator (Translator)
W7 | Aug 03 | [Lab 7]() | CENTRAL Ask Jarvis (Bot Framework, LUIS)
W8 | Aug 10 | [Lab 8]() | CENTRAL Precog 1 (Machine Learning)
W9 | Aug 17 | [Lab 9]() | CENTRAL Precog 2 (Machine Learning) 
W10 | Aug 24 | n/a   | Class IoT Hackathon: Smart Cities
# Week 1

Welcome to Week 1 everyone... it's going to be a fun ride, please provide feedback along the way.

- [Lab 1](lab1/README.md) - RPi, SenseHAT, and MQTT Revisited with a little Node.js
- [Lab 2](lab2/README.md) - Desktop Applications for Visualization with Electron

# Homework

- Setup a different MQTT topic to send/receive data from. Have the RPi send SenseHAT data to this new topic and have your Electron application use the new topic to recieve the data.
- Show Electron app working with a screenshot showing Node version, Chrome version, and Electron version.

![Example Homework](assets/homework1-example.png)
# RPi, SenseHAT, and MQTT Revisited with a little Node.js

## Overview

This lab is to get us collectively back to a stable point with our RPis and make sure everyone is on the same page. All version, libs, etc are running smoothly. We will run through some previous labs to get us up and running, these files have been modified to fit the Course 3 theme and focus only on their specific use case

Some files require system `python` dependencies to be installed. These were covered in Course 1, however, here are links to the packages.
- `mqtt` library can be found at the [Paho MQTT site](https://pypi.python.org/pypi/paho-mqtt/1.1#installation).
- `sense-hat` library can be found at the [SenseHAT site](https://github.com/RPi-Distro/python-sense-hat).

**Note**: Originally some files attempted to detect hostname and that worked well in class, but doesn't work well outside of class so this was removed in favor of a more manual approach. 

## Lab Links

- [MQTT python module](https://pypi.python.org/pypi/paho-mqtt/)
- [SenseHAT python module](https://github.com/RPi-Distro/python-sense-hat)
- [Node](https://nodejs.org/en/)
- [NPM](https://www.npmjs.com/)
- [MQTT npm module](https://github.com/mqttjs/MQTT.js)

## Use Case

Send and receive sensor data from device gateways across the city.

## Read SenseHAT data (from Course 1)

Let's find a file that grabs all the data we need from the SenseHAT and provides a JSON object we can use to send to a MQTT broker. Luckily, we built something similar in Course 1!

This file has been added for your convenience as `centralEdgeV1DeviceTest.py` within this directory. 

## Sending test data via MQTT client (from Course 2)

Let's try something a little different, we've converted a `python` file from Course 2 to be written in `javascript` that we will run on the RPi using `node` for the runtime.

This file has been added for your convenience as `centralEdgeV1-mqttTest.js` wthin this directory.

### Install Node.js and NPM

The following commands will install `node` and `npm` binaries to your RPi.

```bash
pi$ curl -sL http://deb.nodesource.com/setup_4.x | sudo -E bash
pi$ sudo apt-get -y install nodejs
```

### Verify successful installation

```bash
pi$ node --version
# v4.8.3
pi$ npm --version
# 2.15.11
```

### Install dependecies via `npm`

Run the following command from the **week1/lab1** folder.

```bash
~host/week1/lab1: $ npm install
```

### Run the code

Run the following command from the **week1/lab1** folder.

```bash
~host/week1/lab1: $ node centralEdgeV1-mqttTest.js
# Exit with CTRL+C
``` 

## Setup a MQTT Client and send SenseHAT data

Time to send some real data over the interwebs!

Using the `centralEdgeV1-Client.py` file provided, modify the `hostname` variable to include your own. We will use a topic channel of **iot-310b** with a subtopic of your hostname.


## Setup a MQTT Server for the RPi and Receive Other SenseHAT data

Have the RPi listen to other RPi messages (we've done this before, but good practice). 

Using the `centralEdgeV1-Server.py` file provided, modify the `hostname` variable to include your own. We will use a topic channel of **iot-310b** with a subtopic of your hostname.

## HACKER EDITION: Error Handling for MQTT Server

Currently, `centralEdgeV1-Server.py` will work fine for strings that contain JSON objects (as it will pase those JSON objects and turn it into a Python dictionary), however if a non-JSON compliant payload is sent it fails and exits. Update the code to support handling of general text (i.e. disregard non-JSON payloads).# Lab 2 - Desktop Applications for Visualization with Electron

## Use Case

City field reps require a desktop maintenance app to evaluate assets (sensor) functionality.

## Objectives 

- Learn the basics of Electron
  - Test out a demo app
  - Setup a starer project
- Have an editable dashboard Electron app that you can modify to your needs - codenamed **CENTRAL FieldView** for our class.

## Requirements

- Windows, Mac, or Linux machine

## Lab Links

- [Bootstrap 4 alpha](https://v4-alpha.getbootstrap.com/)
  - CSS framework used for styling
  - Installed via an [bootstrap npm module](https://github.com/twbs/bootstrap) within `package.json`
  - [Bootstrap Dashboard template](https://v4-alpha.getbootstrap.com/examples/dashboard/)
    - Click file **Save As > Web Page Complete** within your browser  to save HTML file with corresponding CSS links remove styling/presentation to liking.
  - [More boostrap starter examples](https://v4-alpha.getbootstrap.com/examples/)
- [Electron](https://electron.atom.io/)
  - Quick start guide can be found on home page
- [Node](https://nodejs.org/en/)
- [NPM](https://www.npmjs.com/)
- [MQTT npm module](https://github.com/mqttjs/MQTT.js)
- [WebSockets](https://en.wikipedia.org/wiki/WebSocket)

## What is NPM?

`npm` makes it easy for JavaScript developers to share and reuse code. We will be using `npm` (Node.js Package Manager) to assist us in downloading packages our applications we need. Additionally, NPM has a ton of reusable Node.js modules and libraries we can use. 

If you’re familiar with any package manager “npm” works in a similar way (e.g. `apt` on Ubuntu Linux) . GUI versions of this are  Apple’s App Store, Microsoft’s Windows Store, and Google’s Play store -- they all download other packages not on your computer and install any dependencies that the package may require may have.

To get a high-level understanding of what NPM is doing for you with regards to package managing, watch the video on this link: 
- [https://docs.npmjs.com/getting-started/what-is-npm](https://docs.npmjs.com/getting-started/what-is-npm)

If you'd like to dive deeper (optional), here is a link that explains more on NPM:
- [https://www.sitepoint.com/beginners-guide-node-package-manager/](https://www.sitepoint.com/beginners-guide-node-package-manager/)


## Electron Overview

Electron enables you to create desktop applications with web technologies you know! HTML/CSS/JS! There is also a rich set of operating system APIs you can use (which we won't cover now). Electron uses Node.js runtime for the backend and Chromium for the frontend.

### Anatomy of an Electron app

An Electron app reflects a folder structure similar to a NodeJS application structure. If you don't have direct experience with that, no worries -- let's break it down.

**Example project structure**

```text
your-app/
├── package.json
├── main.js
└── index.html
```

**Example `package.json`**

```json
{
  "name"    : "your-app",
  "version" : "0.1.0",
  "main"    : "main.js"
}
```

The file that describes all the required dependecies/packages needed to run/install the Electron app are within `package.json`. 

There is a default `main.js` that will load the `index.html` file as well. These two files will recieve the bulk of the updates/edits.


## Electron Demo App

### Download Electron Demos

Before you go down the process of working with Electron, it's best to see a final product. *Visual Studio Code*, *Atom* and *Slack* are popular desktop application  examples created using Electron (*Fun Fact: GitHub was originally called Atom Shell, used to build out Atom*).

Download the [Electron Demos App](https://github.com/electron/electron-api-demos/releases) to get a feel for what Electron can do (it shows off native OS API calls too!). Download the latest version (1.3.0 at time of writing) for your OS.

## Electron Quick Start app

Everything related to this guide is from the perspective of a field worker who has as laptop (we will use `$host` as an indicator) with internet connection. So run this on your laptop, not on the RPi.

### Install NodeJS

Follow the instructions at [https://nodejs.org/](https://nodejs.org/) to install Node.js (please install the **Current** release, v8.1.2 at time of writing). Downloads are available for Windows, Mac, and Linux.

Installing Node.js will also give you a package manager called `npm`.

Verify Successful Installation using the following commands:

```bash
host$ node --version
# v8.1.2
host$ npm --version
# v5.0.3
```

### Setup the Electron Quick Start app

This is verbatim from the [Electon Quick start](https://github.com/electron/electron-quick-start) website. It's a simple easy way to setup a minimal Electron app with file defaults, recommended folder structure, and preconfigured settings.

```bash
# Clone the Quick Start repository
host$ git clone https://github.com/electron/electron-quick-start

# Go into the repository
host$ cd electron-quick-start

# Install the dependencies and run
host$ npm install && npm start
```

A window should popup (your Electron app) and it should say "Hello, World!"

The command `npm start` is calling the following area of the file `package.json`. The value of `start` is `electron .`, so npm will fire that command on the terminal as if you wrote it.

```javascript
...

"scripts": {
    "start": "electron ."
  },

...
```

**Example Electron Starter App screenshot**

![ElectronStartApp](../assets/electron-quick-start.png)


## Setup CENTRAL FieldView app

For the purposes on this class, I've included all the necessary items from the git repo of [Electon Quick start](https://github.com/electron/electron-quick-start) so it's easier to work with to start *(e.g. Bootstrap 4 has already been added to the package list)*. Feel free to download the quick start in a separate folder so you can see what it contains and how it was mixed together for our purposes.

### MQTT npm module

To communicate over MQTT on the web we're going to use [WebSockets](https://en.wikipedia.org/wiki/WebSocket), specifically we going to send MQTT over WebSockets. Instead of creating and writing this from scratch, someone has already graciously created a library that just this.

The [MQTT npm module](https://github.com/mqttjs/MQTT.js) allows us to communicate on MQTT over WebSockets. This is our first `npm` module. The `mqtt` npm module (i.e package)  is a library that someone wrote and uploaded to the npm registry (place where you can download npm modules. When you call `npm install [package]` it finds that package and downloads it to a folder called `node_modules`. 

This package/dependency is defined within the `package.json` file. This was added to the `package.json`  file using the command `npm install mqtt`.

```javascript
...

"dependencies": {
    "bootstrap": "^4.0.0-alpha.6",
    "mqtt": "^2.9.0"
  },

...
```

#### MQTT over WebSockets

Open the file `centralView.html` within a text editor and notice that we are connecting to the MQTT server over WebSockets (another application layer protocol in the same vien as HTTP)! WebSockets will allow us to multiplex requests/responses to another server and keep a long lasting connection open. Most modern MQTT brokers provide WebSockets support.

**Example of MQTT broker url from `centralView.html`**

```javascript
var wsMQTTConnectionString = "ws://iot.eclipse.org:80/ws"
```

Also notice which MQTT topic we are subscribing to (**Note**: This will help in homework)

```javascript
var topic = 'iot-310b'
```

#### Install packages

Make sure you are within the **week1/lab2** folder as `npm` creates a folder called `node_modules` where it stores all the binaries for the packages installed. All packages to be installed are listed under `package.json`.

**Note**: Guide assumes you have already cloned this repo.

```bash
# Install dependencies
~host/week1/lab2:$ npm install
# Install electron globally
~host/week1/lab2:$ npm install electron -g
```

#### Run Electron app

Start the Electron app with:

```bash
~/host/week1/lab2:$ npm start
```

The previous command will start the Electron app. To see what's happening go to the file `package.json`.

Electron will first try to execute whatever value is set for `"main"` (typically `main.js`). If a value isn't provided, it will attempt to load `index.js`. 

If you review the `main.js` file, you can notice where the `centralView.html` webpage is being called and loaded.

```javascript
...

 // and load the index.html of the app.
  mainWindow.loadURL(url.format({
    pathname: path.join(__dirname, 'centralView.html'),
    protocol: 'file:',
    slashes: true
  }))
...

```

**Tips**:
- To exit the Electron app, go to the Electron File Menu and select "Electron" and "Quit/Exit".
- Edit HTML/CSS/JS files and hit the refresh shortcut on your computer to see it reflected within the app.

#### Verify CENTRAL FieldView app is receiving incoming MQTT message

The app is configures to listen on `iot-310b` topic. You should see messages coming through (provided messages are sending through).

![Example Working](../assets/exampleMQTTfieldview.png)

## HACKER EDITION: App Distribution

**Note**: Hacker Edition assignments are optional, don't count for anything but give you a starting point for where you should head next. If you'd like to use this in a professional setting.

Package your Electron app for distribution!!!
[https://github.com/electron/electron/blob/master/docs/tutorial/application-distribution.md](https://github.com/electron/electron/blob/master/docs/tutorial/application-distribution.md)# Week 2: Virtual Machines and Containers

Welcome to Week 2 everyone... it's going to be a fun ride, please provide feedback along the way.

- [Lab 1: Intro to Virtual Machines](lab1/README.md) 
- [Lab 2: Intro to Containers](lab2/README.md)

# Homework

*Note*: The homework can be turned in via screenshots, links to repos, and/or any other reference links. 

1. Modify the shell script in **lab1** inside `Vagrantfile` and install a non-installed Ubuntu package via `apt-get`. Take a screenshot of a successfully installed package. Along with a link to your `Vagrantfile`

2. Using your **centralView** dekstop app from Week1/Lab2, setup a custom MQTT topic that receives data from two new virtual devices:
    - One from a VM (instantiated with Vagrant/VirtualBox) - send a screenshot with VirtualBox GUI showing your VM and the message coming into centralView.
    - One from a container (instantiated from Docker) - send a screenshot of the output of `host$ docker ps -a` that should show a "Running" container. Have that adjacent to your centralView.# Intro to Virtual Machines

**Note**: To expedite speed of downloading the base Virtual Machine, run the following command now (after installing Vagrant from [https://www.vagrantup.com/downloads.html](https://www.vagrantup.com/downloads.html))

```bash
host$: vagrant box add ubuntu/xenial64
```

## Overview

This lab will help you get oriented with virtual machines using Vagrant to drive Virtualbox VMs that will ultimately run Ubuntu. We will be able to access the VM directly from terminal and control it. 

Virtual machines are a critical piece to modern cloud infrastructure, in these labs we'll be doing this all locally.

If you've ever setup a Virtual Machine before on your machine, you know that the process goes like this:

1. Download a hypervisor (e.g. VirtualBox, VMWare)
2. Download an ISO of your preferred OS (e.g. Ubuntu/CentOS) to virtualize.
3. Mount the ISO.
4. Walk through the OS installation process.
5. Have a new virtualized OS to do development on.
6. Install packages and system dependecies that your app needs.
7. Launch app and ensure everything is configured properly.
8. Completely forget everything you did on the VM and now never want to destroy it or mess too much with it because you're afraid it'll get into a bad state.
9. To prevent bad states, you snapshot the hell out of it.
10. You now move around a giant VM and all the baggage that it carries (e.g. large disk space, config files, etc)

This results in a "pet" and not "cattle" -- I'll explain this shortly. A  "pet" that you currently have today is your Raspberry Pi. If I told you to flash the SD card with another OS, some of you would be hesitant. Rightfully so, you've spent all this time configuring it, setting it up, and getting it "just right".

"In the old way of doing things, we treat our servers like pets, for example Bob the mail server. If Bob goes down, it’s all hands on deck. The CEO can’t get his email and it’s the end of the world. In the new way, servers are numbered, like cattle in a herd. For example, www001 to www100. When one server goes down, it’s taken out back, shot, and replaced on the line." -- Randy Bias, [The History of Pets vs Cattle](http://cloudscaling.com/blog/cloud-computing/the-history-of-pets-vs-cattle/)

Today, we're going to make some cattle.

## Lab Links

- [VirtualBox](https://www.virtualbox.org/wiki/Downloads)
- [Vagrant](https://www.vagrantup.com)
    - [Docs](https://www.vagrantup.com/docs/index.html)
    - [Boxes](https://app.vagrantup.com/boxes/search)
        - A registry where people upload VMs that have already have a "base" image. An example of a "base" image is downloading an Ubuntu box which already has Ubuntu installed and configured (as well as loading your Vagrant ssh keys).
    - [Provisioners](https://www.vagrantup.com/docs/provisioning/basic_usage.html)
        - Provisioners allow you use to a configuration management tool of your choice (e.g. Chef, Ansible, Puppet, etc) for provisioning a VM. We will not go too deep into this and will use only the shell scripting via Bash.
- [Ubuntu](https://www.ubuntu.com/)
    - We will use Ubuntu 16.04 for virtual machines and containers.
    - [apt - Ubuntu Package Manager](https://help.ubuntu.com/community/AptGet/Howto)

## Use Case

For development purposes, provide a consistent way of provisioning VMs.

## VirtualBox

We will use VirtualBox as our hypervisor to virtualize the Linux operating system Ubuntu. VirtualBox is available for Mac, Windows and Linux.

### Install VirtualBox

- Go to [VirtualBox Downloads](https://www.virtualbox.org/wiki/Downloads) to download VirtualBox for your specific host.
    - Install VirtualBox via the downloaded binary.
- After installing VirtualBox download the [VirtualBox Extension Pack](https://www.virtualbox.org/wiki/Downloads)
    - Install extension pack onto VirtualBox using the downloaded binary.

## Up and Running with Vagrant

### Overview

**Note**: The following guide on Vagrant is not to be used for provisioning or scaling production VMs. 

"Vagrant is a tool for building and managing virtual machine environments in a single workflow. With an easy-to-use workflow and focus on automation, Vagrant lowers development environment setup time, increases production parity, and makes the "works on my machine" excuse a relic of the past." [Source](https://www.vagrantup.com/intro/index.html)

We will use Vagrant to automate virtual machine provisioning of VirtualBox VMs.

### Install Vagrant

Download Vagrant at [https://www.vagrantup.com/downloads.html](https://www.vagrantup.com/downloads.html) for your specific host. Install using the downloaded binary.

### Initialize a `Vagrantfile` and Create a Virtual Machine

The following commands will:
- Initialize this current folder with a `Vagrantfile`
- Download a [Vagrant Box](https://app.vagrantup.com/boxes/search)
    - **Note**: This process may take a while depending on connection speed.
- Startup the VM.

```bash
host ~week2/lab1$ vagrant init ubuntu/xenial64
host ~week2/lab1$ vagrant up
```

After running the above two commands, you will have a fully running virtual machine in VirtualBox running Ubuntu 16.04 LTS 64-bit. 

The `vagrant up` command references a file called `Vagrantfile` that was created in this folder when we initialized this folder for Vagrant using `vagrant init [BOX IMAGE]`. In this case, we told it to pull down the Vagrant Box image from [Vagrant Box](https://app.vagrantup.com/boxes/search). To learn more about Vagrant Boxes click [here](https://www.vagrantup.com/intro/getting-started/boxes.html).

You can verify this visually by opening the VirtualBox application on your host machine. You will see a VM state of "running" and the operating system will say "Ubuntu 64-bit".

![vagrant-vbox](../assets/virtualbox-vagrant.png)

### Accessing the VM

SSH into the VM!

```bash
# Assumes VM is running
host ~week2/lab1$ vagrant ssh
```

From here, you can do whatever you would normally want to do with an Ubuntu Linux machine. 

```bash
# Assumes ssh'ed into VM, play around!
ubuntu@ubuntu-xenial:~$ echo "Hello, world!"
ubuntu@ubuntu-xenial:~$ uname -a 
```

Exit the VM:

```bash
ubuntu@ubuntu-xenial:~$ exit 
```

### Halt the VM, Destroy the VM

We mentioned earlier about "pets" vs "cattle" and we're going to show it now. We'll stop the VM, destroy it, and in the next section setup new provisioning steps for the new VM instance to follow.

Halt the VM:

```bash
# Assumes VM is running
host ~week2/lab1$ vagrant halt
```

Verify the VM is powered off (or you can look at VirtualBox GUI):

```bash
host ~week2/lab1$ vagrant status

# Current machine states:
# default                   poweroff (virtualbox)
```

Now destroy the VM instance!

```bash
# Assumes VM is powered off
host ~week2/lab1$ vagrant destroy
# default: Are you sure you want to destroy the 'default' VM? [y/N] y
# ==> default: Destroying VM and associated drives...
```

So what did the command destroy? It destroyed the instance of our VM, however our "base" image (i.e. Vagrant box) that we initially used to build the VM is still available locally. Which means we can build another instance using this base image and provision another VM instance.

```bash
host ~week2/lab1$ vagrant box list
# ubuntu/xenial64 (virtualbox, 20170626.0.0)
```

## Provisioning the VM

Now let's use what we've learned to create a new VM, except now we'll add custom provisioning.

**Note**: The `Vagrantfile` is written in Ruby, so it's sometimes helpful to change your syntax highlighting to "Ruby" when working in the file.

Open `Vagrantfile` and change the following lines (which are commented out near the bottom of the file):

```ruby
# config.vm.provision "shell", inline: <<-SHELL
#   apt-get update
#   apt-get install -y apache2
# SHELL
```

To the following:

```ruby
config.vm.provision "file", source: "centralVirtualDevice.py", destination: "centralVirtualDevice.py"

config.vm.provision "shell", inline: <<-SHELL
    # Celebrate!
    echo "I provisioned a headless VM using Vagrant!"

    # Update list of packages
    apt-get update

    # Install python
    # Note: "-y" option is used since we are not in an interactive session.
    #   This will tell the apt-get installer to say "Y" when input is expected
    apt-get install -y python

    # Download pip for Python 2
    wget https://bootstrap.pypa.io/get-pip.py

    # Install pip for Python 2
    python get-pip.py

    # Install Python MQTT client
    pip install paho-mqtt

    # Check version
    python --version
SHELL
```

Create a new VM instance:

```bash
host ~week2/lab1$ vagrant up
# ...
# ==> default: Setting up libpython-stdlib:amd64 (2.7.11-1) ...
# ==> default: Setting up python (2.7.11-1) ...
# ==> default: Python 2.7.12
# ...
```

What did this do? It updated all the Ubuntu apt packages lists, installed the preferred Python version for this version of Ubuntu, verified installation of Python, added our file called `centralVirtualDevice.py` along with dependencies we need to run that file on a new machine (e.g. `pip` and `paho-mqtt`). 

You can access the VM via SSH and run the Python file:

```bash
host ~week2/lab1$ vagrant ssh

ubuntu@ubuntu-xenial:~$ ls
# centralVirtualDevice.py

ubuntu@ubuntu-xenial:~$ python centralVirtualDevice.py
```

You now know how to work on VMs in an effective manner for local development.

Feel free to shutdown your VM if you want:

```bash
# Assumes VM is running
host ~week2/lab1$ vagrant halt
```

## Troubleshooting

If you delete the `Vagrantfile` before destroying your VM you can put yourself in a bad situation (i.e. Vagrant doesn't know how to drive VirtualBox and all references are gone). If that happens, remove the VM from the VirtualBox GUI. Ideally, delete VM instance using `vagrant destroy` and then delete the `Vagrantfile` (if you wanted to). Also, don't make changes inside of VirtualBox GUI, all options and configs should be defined within the `Vagrantfile`.


## Hacker Edition (optional): VirtualBox Settings, Networking and Synced Folders

Set VirtualBox configs 
(e.g. memory/cpus) using: [https://www.vagrantup.com/docs/virtualbox/configuration.html](https://www.vagrantup.com/docs/virtualbox/configuration.html)

Other areas to learn that are extremely helpful are:
- [Networking](https://www.vagrantup.com/intro/getting-started/networking.html)
- [Synced Folders](https://www.vagrantup.com/intro/getting-started/synced_folders.html)
- [Shell External Scripts](https://www.vagrantup.com/docs/provisioning/shell.html#external-script)# Intro to Containers

## Overview

This lab will help you get oriented with Docker and why we are using it. 

## Lab Links

- [Docker](https://www.docker.com/)
- [Docker Hub Registry](https://hub.docker.com/)
    - Images uploaded to this registry are maintained by the community and have no support from Docker directly.
- [Docker Store](https://store.docker.com/)
    - This link is only provided as a reference. More details on Docker Store can be found [here](https://docs.docker.com/docker-store/).
    - The Docker Store provides Docker Verified images (as well as access to Docker Hub images). These Docker Verified images are verified by Docker, have a high level of security, and generally subscribe to Docker best practices.
    - In an enterprise setting, this likely would be the route to choose (as depending on publisher) may include a paid support level.

## Use Case

Investigate a way to optimize application density at the edge devices.

## Docker Overview

"Docker provides a method of developing, shipping, and running applications. Docker provides the ability to package and run an application in a loosely isolated environment called a container. The isolation and security allow you to run many containers simultaneously on a given host. Containers are lightweight because they don’t need the extra load of a hypervisor, but run directly within the host machine’s kernel. This means you can run more containers on a given hardware combination than if you were using virtual machines. You can even run Docker containers within host machines that are actually virtual machines!" [Source](https://docs.docker.com/engine/docker-overview/)

In the context of Docker, an **image** is the binary file that contains your code, your code packages, and any system level dependencies. A **container** is an instance of an image. 

This will make more sense during the lab. Right now, it's important to note that at a high-level the following points are key takeaways for containers [Source](https://docs.docker.com/engine/docker-overview/#what-can-i-use-docker-for):

- Fast, consistent delivery of your applications
    - Work in standardized environments using local containers which provide your applications and services.
- Responsive deployment and scaling
    - Because of the portability and how lightweight Docker is, you can dynamically manage workloads, scale up/tear down services with ease in near real-time.
- Running more workloads on the same hardware
    - You can increase app density on the same hardware over hypervisor-based virtual machines, so you can use more of your compute capacity to achieve your business goals. Docker is perfect for high density environments and for small and medium deployments where you need to do more with fewer resources (e.g. the Raspberry Pi).

Let's get into it!

## Docker Overview

Docker project (open-sourced by dotCloud in March '13) consists of several main parts (applications) and elements (used by these parts) which are all [mostly] built on top of already existing functionality, libraries and frameworks offered by the Linux kernel and third-parties (e.g. LXC, device-mapper, aufs etc.).

### Main Docker Parts

- docker daemon: used to manage docker containers on the host it runs
- docker CLI: used to command and communicate with the docker daemon
- docker hub registry: a repository (public or private) for docker images
- docker store: a trusted repository of images maintained by docker or first-party developers

### Main Docker Elements

- docker containers: directories containing everything-your-application
- docker images: snapshots of containers or base OS (e.g. Ubuntu) images
- Dockerfiles: scripts automating the building process of images

## Installing Docker

We will install the **Docker Community Edition** on your host machine. You can download it here: [Docker Community Edition](https://www.docker.com/community-edition).

Verify successful installation by opening your host machine's shell and enter:

```bash
host$ docker run hello-world
```

You will see some output similar to:

```text
Hello from Docker!
This message shows that your installation appears to be working correctly.
...
```

You can search for images available on Docker Hub by using the docker command with the `search` subcommand. For example, to search for the Ubuntu image, type:

```bash
host$ docker search ubuntu   
```

Alternatively, you can search on the [Docker Hub Registry](https://hub.docker.com/) website.

In the OFFICIAL column, OK indicates an image built and supported by the company behind the project. Once you've identified the image that you would like to use, you can download it to your computer using the `pull` subcommand, like so:

```bash
host$: docker pull ubuntu
```

After an image has been downloaded, you may then run a container using the downloaded image with the `run` subcommand. If an image has not been downloaded when docker is executed with the `run` subcommand, the Docker client will first download the image, then run a container using it:

```bash
host$: docker run ubuntu
```

To see the images that have been downloaded to your computer, type:

```bash
host$: docker images
```

The output should look similar to the following:

```text
Output
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
ubuntu              latest              d355ed3537e9        7 days ago          120.8 MB
hello-world         latest              1815c82652c0        2 weeks ago         967 B
```

The `hello-world` container you ran in the previous is an example of a container that runs and exits, after emitting a test message. Containers, however, can be much more useful than that, and they can be interactive. After all, they are similar to virtual machines, only more resource-friendly.

As an example, let's run a container using the latest image of Ubuntu. The combination of the -i and -t switches gives you interactive shell access into the container:

```bash
host$: docker run -it ubuntu
```

Your command prompt should change to reflect the fact that you're now working inside the container and should take this form:

```bash
root@33b7ca72ea69:/#
```

Important: Note the container id in the command prompt. In the above example, it is 33b7ca72ea69.

Now you may run any command inside the container. For example, let's update the package database inside the container. No need to prefix any command with sudo, because you're operating inside the container with root privileges:

```bash
container$: apt-get update
```

Then install any application in it. Let's install NodeJS, for example.

```bash
container$: apt-get install -y nodejs
```

This command pulled an [Ubuntu image from Docker Hub](https://hub.docker.com/_/ubuntu/). Docker uses a file called `Dockerfile` to describe how a Docker image should consist of, we'll see more of this later.

You can already see how powerful this can be... you've downloaded an Ubuntu environment that acts and works very similar to an Ubuntu VM except much more lightweight than the VMs.

In the next step we'll recreate what we did in Lab 1 but within containers.

## Containerize `centralVirtualDevice.py`

Let's go ahead and download a Docker container that already has Python 2.7 installed. 

Open the included file called `Dockerfile`, go line by line and read what is happening. We can add more comments if necessary, but at a high-level it's equivalent to the provisioning we did within the `Vagrantfile`.

Because we created our own `Dockerfile` we need to build a image and have Docker run all the commands we have told it. The following command will build the image (layer by layer), tag it with a name, and use the `Dockerfile` in the current directory.

```bash
host ~/week2/lab2$ docker build -t central_virtual_device .
```

Look at the new image you've made at:

```bash
host$ docker images
```

Now run your container:

```bash
host$ docker run -it central_virtual_device
```

This will instantiate a new container based off of the `central_virtual_device` image and will latch onto your terminal. 

If you want to run in a daemonized mode, run:

```bash
host$ docker run -d central_virtual_device
```

## Pushing up to Docker Hub

We can also push the image we created to Docker Hub.

- [Signup for Docker Hub](https://hub.docker.com/)

You can now log into Docker Hub from the terminal:

```bash
# Use the username and password you used in Docker Hub
host$ docker login
```

We are going to add another tag for our custom image that will work with Docker Hub Registry

```bash
# Usage: docker tag [image] [new image name]
#   Example: docker tag central_virtual_device [dockerHubUsername]/central_virtual_device
host$ docker tag central_virtual_device richardjortega/central_virtual_device
```

We can push your image up to Docker Hub so other people can download it:

```bash
host$ docker push richardjortega/central_virtual_device
```

I can now view my uploaded image at Docker Hub: [https://hub.docker.com/r/richardjortega/central_virtual_device/](https://hub.docker.com/r/richardjortega/central_virtual_device/)

Other people can directly pull the image and run on their machine:

```bash
host $: docker pull richardjortega/central_virtual_device
```

## Hacker Edition: Learn about adding app data within containers

- Add a `test.txt` file (with your own arbitrary text) to the image we created using `Dockerfile`. Upload the new image to DockerHub and provide a link to your DockerHub.
    - Tip: Use `COPY` command: [https://docs.docker.com/engine/reference/builder/#copy](https://docs.docker.com/engine/reference/builder/#copy)

- In a standard development workflow with Docker, developers will typically mount their host's application  folder to the container's application folder providing a way to edit code locally on the host and it reflecting immediately within the container.
    - You can read more about this on [Manage data in containers](https://docs.docker.com/engine/tutorials/dockervolumes/) under the section [Mount a Host Directory as a Data Volume](https://docs.docker.com/engine/tutorials/dockervolumes/#mount-a-host-directory-as-a-data-volumeMount)